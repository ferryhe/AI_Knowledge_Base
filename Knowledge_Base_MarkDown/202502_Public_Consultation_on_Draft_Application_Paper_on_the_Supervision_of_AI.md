# IAA_Response_IAIS_Public_Cnsltn_Draft_Applic_Paper_AI_17Feb2025

## Page 1
# Public consultation on draft Application Paper on the supervision of artificial intelligence 

## Survey response 1

Please provide your information:
Name: - Amali Kaushala Seneviratne
E-mail address: - amali.seneviratne@actuaries.org
Name of jurisdiction: - International
Name of organisation: - International Actuarial Association (IAA)
Do you agree with your responses being made public on the IAIS website?
Yes

## General comments on the draft Application Paper on the supervision of artificial intelligence

## General comments on the Application Paper

The draft paper is well-structured and provides a well-constructed guide for navigating Al supervision within the insurance sector. However, further points for consideration are:
$\checkmark$ That illustrate effective Al governance frameworks in practice.
$\checkmark$ The concept of proportionality and risk-based supervision is mentioned, suggesting varying degrees of scrutiny based on risk levels. Clear criteria or examples supporting this principle would assist supervisors in applying proportional oversight effectively. $\checkmark$ Improve consistency among sections, with clear definitions on terms such as traceability, transparency, explainability and robustness

## Section 1 Executive Summary

## General comments on Executive Summary

The Executive Summary effectively sets the stage for the document by addressing the potential benefits of Al in the insurance sector. In addition:
$\checkmark$ The Executive Summary could consider articulating a more strategic vision for the future of Al within insurance. This could include aspirations for ensuring ethical Al use, maintaining consumer trust, and navigating the regulatory landscape effectively. A forward-looking perspective would inspire confidence in the direction proposed by the IAIS.
$\checkmark$ Point 2: "... where it becomes difficult to trace decisions or actions back to human operators" - this could be rephrased, putting emphasis on the difficulty to trace decisions as a result of complex Al algorithms, rather than creating a link between tracing decisions and human operators.
$\checkmark$ "However, with these advancements come notable risks that could detrimentally impact the financial soundness of insurers (see paragraph 9) and consumers as well)." The last bracket can be deleted.
$\checkmark$ The Executive Summary overall does not reflect the contents of the Paper. For example, point 4 focuses on education and thirdparty risk, where the scope of the Paper is broader and provides guidance on the four boxes of the Al Governance framework. Table 1 perfectly provides an overview of the contents of the paper.
$\checkmark$ Paragraph 2 mentions the potential impact on the financial soundness of insurers, yet the rest of that paragraph seems to relate more to market conduct issues rather than financial soundness. The IAA suggests adding the points on financial soundness mentioned in paragraph 9 below.

## Page 2
# Section 2 Introduction 

## General comments on Section 2

The Introduction articulates well the Paper's purpose and contextualizing the discussion on AI in insurance. Further points to consider are:
$\cdot$I]Case studies on how supervisors handled certain issues w.r.t. different AI systems and their potential impact
$\cdot$IIIncluding an Introduction on the challenges faced by insurers during AI implementation, such as integrating AI into existing systems and aligning it with current regulatory frameworks
These may be addressed in the relevant sub-sections.

## Comments on Section 2.1 Context and objective

-1]2.1 - 7 - Failing to mention applications of Gen AI which, when deployed, can provide different answers, even when using the same input information/data.
-1]2.1 - 7 - second sentence, "There are different types of AI system, ...", AI systems, an "s" is missing.
-1]Box 1: The wording infers that all (existent) prudential risks can be affected by the risks AI-systems pose. For consideration, the following "... and insurers in managing these risks", could be replaced by 'managing the following fundamental risks' or 'managing these risks, which include:'. This would support the fact that not all relevant risks are being mentioned, for example, systemic and strategic risks.
-1]Similarly, for point 9, and Box 1: It states that that AI can introduce new risks or increase existing risks. The wording used in the summary stating that AI can amplify existing risks, is preferred.
-1]Box 1 - \#3 - Model risk/explainability - the preference would be not to combine model risk with explainability as the definition of model risk is broader and can include among others, explainability. Explainability is often mentioned together with transparency.

Comments on Section 2.2 AI system definition

## Comments on Section 2.3 Scope and structure

We offer the following remarks on tables and sub-sections.
Table 1:
$\cdot$I]Adding section numbers to the headers of the boxes could help linking the table to the sections better: 3 to 6.
$\cdot$IIData management is part of the robustness, safety and security section as is also mentioned in point 51.
$\cdot$I"Sufficiency of information from third-party service providers" could be moved from box 3: Transparency and explainability to box 1, under the already listed "Use of third-party AI systems and data'.
$\cdot$IIThe heading of box 3 is Transparency and explainability, and in both the box and Section 5 itself, Transparency is not addressed very much. The terms explainability and transparency are used interchangeably.

Point 15: "An ethical and responsible.." - the IAA suggests deleting 'ethical', given "responsible" includes ethical aspects.
Point 18: The IAA suggests combining this point 18 with 19, including an addition of development risks. In addition, on point 18, "..implementation and use of AI systems by insurers", change to 'AI systems present in the insurance industry' or 'AI systems that relate to insurance activities", given AI systems in general refer to a broader scope than the one of the Paper. Additionally, it could be mentioned that not all risks related to AI are covered, providing some examples (such as systemic risks) - the list under these points is not complete.

Table 2: for better readability, it could be a better idea to highlight the ICPs as a list, or under bullet points, or transfer them to an Appendix and refer to that.

## Comments on Section 2.4 Proportionality and risk-based supervision

An improvement for this section could be to mention the 'Proportionality Principle' - when applying proportionality, the industry could benefit from conducting an AI-risk and harm assessment.

Table 3, Some additional points to consider here are:
$\cdot$IIModel-related section, under Architecture - it could be beneficial to add also some information from the model development perspective, what is good practice when developing models from an architectural point of view;
$\cdot$IITransparency/explainability - Algorithm confidentiality is a good thing, but explainability methods can also be used on a more technical level, resulting in explaining how algorithms work and drive decisions. Disclosing such information to supervisors can result in additional transparency. In addition, this table paragraph could also include some examples of explainability methods, and not only address the explainability and transparency issues.

## Page 3
Comments on Section 2.5 The role of supervisors and supervisory tools
In the bullet point referring to 'cooperation with other authorities', consider including 'coordination' to reflect the opportunity to leverage supervisory resources in a coordinated way.

# Section 3 Governance and accountability 

## General comments on Section 3

This Section provides a comprehensive overview of the essential elements required for effective governance of Al systems in the insurance sector. Further points to consider are:
$\checkmark$ It could be beneficial to include specific examples of successful governance frameworks already in use within the insurance industry or related sectors.
$\checkmark$ Offering practical suggestion how to implement these oversight mechanisms, such as developing an oversight board or specific reporting structures, would add further value to the recommendations
Further elaborate on good practice for managing these third-party relationships, such as due diligence processes, ongoing monitoring of third-party performance, and the importance of contractual safeguards.

These may be addressed in the relevant sub-sections.

## Comments on Section 3.1 Introduction

In paragraph 32, last bullet, the wording talks about the ability of Al to make "rapid decisions". This seems to be counter to the discussion of Al requiring oversight, such that Al should not be allowed to make rapid decisions without some human oversight. Perhaps use the words "rapid evaluations" rather than "rapid decisions"?

## Comments on Section 3.2 Risk management systems

Point 36 - states that "The management of material Al-related risks can be set out in either existing risk management policies (such as within an existing model risk management policy) or an Al-specific policy." The Al-risks can be handled not only in existing or new policies, but also in a mixed version; combining existent with new policies. In addition, the footnote of point 36 in this section specifies/suggests that large insurers are more likely to have specific risk appetite statements, and therefore a specific Al-policy, which in our opinion is out of context here. Al overlaps on many aspects with practices established by well-defined model management policies, and in each phase of a system, model management practices may be able to be used. The paper could suggest that an insurer can manage Al-risks through an existent risk management policy, a specific Al-policy, or inter-linked policies, resulting in a common understanding across control functions. The suggestion is to remain at discussing the relevant content, rather than start a discussion on policy hierarchy.

## Comments on Section 3.3 Corporate culture

Point 39: The first sentence "When implementing a risk-based approach to Al risk management, the Board should promote a corporate culture for fair and ethical outcomes, ensuring a responsible approach to the use of Al." The corporate culture, and implicitly the Board driving this, should also account for other aspects when managing Al-risks, such as account for robustness of Al systems.

## Comments on Section 3.4 Human oversight and allocation of management responsibilities

The section describes human oversight in an optimistic way; an idea could be to name some scenarios and how human oversight can be managed when this is not fully guaranteed. Effective human oversight could be enhanced by validation and testing methods. In addition, is it realistic that the board of directors will have the necessary 'Al' experience as prescribed in this section?
$\checkmark$ Point 41 : data scientists are named here, which is perfectly fine, but not really provided as an example. Other disciplines such as financial quants, actuaries and risk management practitioners can all be responsible for initial Al system deployment. Adding "for example" to the sentence will not exclude other disciplines or cases. In addition, excluding the "Specific areas.." would provide more clarity.
$\checkmark$ Point 41: As mentioned in our earlier comment, there are concerns with the use of Al for important decision-making without human oversight. There might be mention of that concern is this bullet point.
$\checkmark$ Point 42 - an additional bullet could address the risk management function, where appropriate execution of risk management can also be a part of the senior management duties. We also suggest replacing "Defining the Board's role throughout an Al system's life cycle" by "Defining the Board's role for the responsible use of Al".

## Comments on Section 3.5 Use of third-party Al systems and data

A remark on subsection 3.5.1. - Point 44: A third-party provider can disclose information under NDA agreements, aligning with the risk management and control functions of the insurer; the same or similar information can be disclosed by the third-party to the correspondent supervisor.

Section 3.5.2 discusses Third-party concentration risks in the context of concerns for the insurer. This section could also discuss relevant concentration concerns for the supervisor. A concentration in the use of a single or limited number of Al vendors could result in systemic risks for the market, which should be a concern for the supervisor of that market.

## Page 4
# IAISS 

## Comments on Section 3.6 Traceability and record keeping

We recommend highlighting in an introductory part that reproducibility and traceability of Al systems depends heavily on their complexity. Addressing issues of data, self-learning capabilities and reproducibility of outcomes is a complex process, and depends on system complexity.

Point 48: Another way a supervisor could get access to the managing process of a system is through reporting that relates to how AI models are being operationalized. DevOps, or more modern MLOps practices are now implemented in software frameworks to integrate and automate software development. This agile approach can help supervisors get faster and better insights in different model metrics, and add an extra traceability when it comes to the life cycle of models. As a supervisor, industry standards can be developed to further assess, through standard reports, each step of such a DevOps process/environment - from data management, model development, training, testing, to monitoring and operating.

## Section 4 Robustness, safety and security

## General comments on Section 4

This Section provides a good examination of the essential factors necessary for ensuring the reliability and protection of Al systems. Consider strengthening this Section by elaborating on the below:
$\checkmark$ Specific metrics or key performance indicators (KPIs) that insurers should track to assess the robustness and safety of their Al systems continually.
$\checkmark$ Guidelines tailored to generative AI and large language models to tackle the unique risks they present.
$\checkmark$ Implementation examples could enhance the practical application of the recommended security measures, assisting insurers in effectively integrating these strategies into their operations
These may be addressed in the relevant sub-sections

## Comments on Section 4.1 Introduction

The IAA suggest including a link to ICP 8 and ICP 19.

## Comments on Section 4.2 Al system robustness

## Comments on Section 4.3 Al system safety and security

$\checkmark$ Similarly to section 4.2, having a subsection "4.3.1 Segmentation and compartmentalisation" as a sub-title is not necessary. $\checkmark$ Point 59: This guidance on third-party providers is also applicable in other sections such as the testing guidance mentioned by Point 53. This is also generally described in section 3.5, and it can be omitted here. Check also other sections in the paper where an extra reference to third-party providers is made.
$\checkmark$ Point 60: This is not typical for Al, but already an important cyber risk management control.

## Section 5 Transparency and explainability

## General comments on Section 5

This Section provides an important discussion on the transparency and explainability of Al systems, directly linking these elements to fairness, accountability, and consumer trust. Further guidance on implementation strategies and a focus on new technologies would enhance the section's practical application:
$\checkmark$ How organizations have overcome these challenges in practice, including specific techniques or methodologies used to enhance explainability (e.g., model-agnostic approaches, local interpretable model-agnostic explanations (LIME), or SHAP values)
$\checkmark$ Establishing clear documentation practices, utilizing tools designed for explainability
$\checkmark$ Emphasizing the role of training programs for employees and initiatives to educate policyholders about Al systems
$\checkmark$ Identifying key regulatory bodies and their guidelines with examples of jurisdictions that have established compliance requirements
$\checkmark$ More focus could be placed on the explainability challenges posed by emerging Al technologies, like generative Al and large language models, which often operate beyond conventional explainability tools

These may be addressed in the relevant sub-sections.
Comments on Section 5.1 Introduction

## Page 5
Comments on Section 5.2 Explaining AI system outcomes
The IAA suggests including here a link to ICP 8 and ICP 19.
Generally, the term explainability is used in this section where it should refer to both explainability and transparency as in the referenced ICP 19.10.

Comments on Section 5.3 Explanations adapted to the recipient stakeholders
The aspect of information proportionality is missing here. Less important information requires less explanations, compared to important information. This leads to the central core question, which information is the important and which is less.

# Section 6 Fairness, ethics and redress 

## General comments on Section 6

This section highlights the essential principles guiding the ethical use of AI in insurance.
Some points to consider elaborating on are:
- Further strategies for mitigating bias, such as implementing fairness-aware algorithms or employing diverse datasets during model training.
- Recommendations for integrating ethical considerations into the AI lifecycle-from design to deployment-could encourage more proactive engagement with these issues. Real-world examples or case studies to showcase practical application of the principles discussed, improving comprehension and usability for stakeholders.
- Specific metrics or key performance indicators (KPIs) that organizations can use to assess fairness and ethical impacts continuously.
- Methods for gathering stakeholder feedback and incorporating it into AI decision-making processes.
- The heading and scope could be changed to simply 'Data management' as the management of data risks is broader than only fairness.
- It is preferred to limit the scope of this section to completeness and reliability of the data, and privacy risk, given the importance of data and to prevent overlap with other sections. Privacy risk is also not explicitly covered in this Paper.
- Section 6.4 Inferred causal relations in an AI system should be part of section 4.2 AI system robustness
- Section 6.2 Fairness by design, 6.5 Monitoring the outcomes of AI systems and 6.6 Adequate redress mechanisms for claims and complaints should be added to section 5 making this a section on Outcomes, in line with the former risk assessment overview of this Paper.

Comments on Section 6.1 Introduction

## Comments on Section 6.2 Fairness by design

Point 80, bullet "Governance" - Information on the roles and responsibilities could be added, such as the one defined under section 3.3. Under this section the allocation of management responsibilities is highlighted.
Another idea would be to include metrics (maybe under "Monitoring the outcomes of AI systems") that help understand how fairness connects to an insurer's business needs. (think of threshold optimisation, grid search etc.)
In addition, experimental data sets can be used to exclude second order effects and identify indirect discrimination. By disclosing such information, an insurer can minimize the risk of having unfair algorithms, and risk of bias.

Comments on Section 6.3 Data management in the context of fairness
Point 81 - Post-processing is not only linked to data, but can be linked to model outcomes and model development as well. While these two can be treated separately, mentioning the importance of post-processing related to model development and model outcome could be beneficial here. AI model outputs feed the environment they relate to, pre-environment or post-model processing can cause undesired effects.

Comments on Section 6.4 Inferred causal relations in an AI system

Comments on Section 6.5 Monitoring the outcomes of AI systems

Comments on Section 6.6 Adequate redress mechanisms for claims and complaints

Comments on Section 6.7 Societal impacts of granular risk pricing

## Page 6
# General comments on IAIS work on artificial intelligence 

What further work could the IAIS undertake on artificial intelligence?
The IAIS could consider the below initiatives as future work on AI:
$\cdot$ Establishing a Regulatory Sandbox - Consider supporting local regulators establishing a regulatory sandbox specifically for AI applications in insurance. This would allow insurers to test innovative AI solutions in a controlled environment under regulatory supervision. Additionally, it will also support regulators in regions that have less exposure to an extensive set of AI use cases. - Monitoring and Assessment Framework - Considering supporting local regulators establishing a framework for monitoring and assessing the implementation of AI technologies in the insurance sector. This could involve collecting data on AI usage, outcomes, and risks faced by insurers, thereby facilitating evidence-based policy development.
$\cdot$ Addressing Global Regulatory Harmonization - work towards global regulatory harmonization to create consistent standards for the use of AI in insurance. For example, facilitating discussions among regulators from various countries could lead to the development of unified guidelines.

Are there risks not effectively captured by the IAIS' work on artificial intelligence?
$\cdot$ Cross-Border Regulatory Challenges not currently captured (at least in the paper). As AI technologies are deployed globally, international regulatory inconsistencies can lead to challenges in governance. For example, regulations on cross-border data flows, different regulatory requirements in various jurisdictions, and the challenges posed by global AI applications. - Adding risk - taxonomies for AI systems, addressing more risks such as systemic, strategic etc. - Supporting documentation for countries and regions where data is not available, where insurance gap exists, and how regulators can supervise AI accordingly.


